## 4. Installation de PostgreSQL en local et connexion avec Metabase

Une fois les concepts assimilÃ©s, on passe Ã  un **SGBD rÃ©el (PostgreSQL)** pour manipuler des donnÃ©es via SQL. Chaque Ã©tudiant installera PostgreSQL en local sur sa machine, puis utilisera **Metabase** (outil open-source de visualisation de donnÃ©es) pour interagir avec la base de faÃ§on conviviale.

**Ã‰tape 1 â€“ Installer PostgreSQL localement :** PostgreSQL est un SGBDR libre et multi-plateforme. Selon le systÃ¨me dâ€™exploitation des Ã©tudiants, les instructions dâ€™installation diffÃ¨rent lÃ©gÃ¨rement :

- *Sous Windows*, tÃ©lÃ©charger lâ€™installateur depuis le site officiel PostgreSQL et suivre le wizard (incluant souvent pgAdmin4, un outil graphique dâ€™administration).
- *Sous macOS*, utiliser lâ€™outil Homebrew (`brew install postgresql`) ou le paquet .dmg proposÃ©.
- *Sous Linux*, utiliser le gestionnaire de paquets (ex : `sudo apt-get install postgresql postgresql-contrib` sur Debian/Ubuntu).

Lors de lâ€™installation, il faudra dÃ©finir un mot de passe pour lâ€™utilisateur administrateur (souvent lâ€™utilisateur `postgres`). Une fois installÃ©, PostgreSQL tourne en arriÃ¨re-plan comme un service. On peut tester son fonctionnement en ouvrant un terminal/Invite de commande et en lanÃ§ant le client `psql` (fourni) : par exemple, exÃ©cuter `psql -U postgres -l` pour lister les bases existantes. Par dÃ©faut, une base nommÃ©e *postgres* est crÃ©Ã©e. On peut crÃ©er une nouvelle base de travail avec `CREATE DATABASE test;` (via `psql` ou via pgAdmin).

**Ã‰tape 2 â€“ Installation de Metabase :** Metabase est un outil de BI lÃ©ger qui permet de se connecter Ã  une base de donnÃ©es et dâ€™exÃ©cuter des requÃªtes ou de gÃ©nÃ©rer des tableaux de bord sans programmation. Il sâ€™exÃ©cute soit via un fichier JAR Java (exÃ©cutable sur nâ€™importe quelle machine avec Java installÃ©), soit via une image Docker. Pour simplifier, on peut utiliser le JAR : tÃ©lÃ©charger la derniÃ¨re version de Metabase (fichier `metabase.jar`) et la lancer par `java -jar metabase.jar`. Celui-ci ouvre un service web local (par dÃ©faut sur http://localhost:3000).

Au premier lancement, Metabase guide lâ€™utilisateur pour crÃ©er un compte admin local (email + mot de passe) puis propose de configurer la premiÃ¨re connexion de base de donnÃ©es.

**Ã‰tape 3 â€“ Connexion de Metabase Ã  PostgreSQL :** Dans lâ€™interface web Metabase (une fois connectÃ©), cliquer sur **Administration â†’ Bases de donnÃ©es â†’ Ajouter une base de donnÃ©es**[metabase.com](https://www.metabase.com/docs/latest/databases/connections/postgresql#:~:text=To%20add%20a%20database%20connection%2C,Add%20a%20database). Choisir **PostgreSQL** comme type. Renseigner les paramÃ¨tres de connexion : *nom dâ€™hÃ´te* (ex: `localhost` si PostgreSQL est sur la mÃªme machine), *port* (5432 par dÃ©faut), *nom de la base* (par ex. `test` ou autre si vous avez crÃ©Ã© une base dÃ©diÃ©e), *nom dâ€™utilisateur* (`postgres` ou un autre compte si crÃ©Ã©) et *mot de passe*. Validez la configuration. Si les infos sont correctes, Metabase Ã©tablit la connexion et va analyser automatiquement les tables prÃ©sentes.

Ã€ ce stade, les Ã©tudiants ont une **stack locale fonctionnelle** : un serveur PostgreSQL qui gÃ¨re les donnÃ©es, et Metabase comme interface utilisateur pour interagir avec cette base.

**Ã‰tape 4 â€“ Premiers pas avec SQL via Metabase :** Metabase permet dâ€™exÃ©cuter des **questions** (requÃªtes) en SQL ou via une interface graphique. Pour commencer, crÃ©ez une table dâ€™exemple dans PostgreSQL. On peut soit :

- Utiliser Metabase en mode requÃªte SQL directe (onglet *Native query*), soit
- Utiliser pgAdmin ou `psql` pour exÃ©cuter la commande SQL de crÃ©ation.

Par exemple, dans Metabase on peut aller dans *Write SQL* et exÃ©cuter :

```sql
CREATE TABLE exemple_personnes (
  id SERIAL PRIMARY KEY,
  nom VARCHAR(100),
  age INT
);

```

Cela va crÃ©er une table *exemple_personnes* avec trois colonnes. Metabase dÃ©tectera la nouvelle table (on peut rafraÃ®chir le schÃ©ma dans lâ€™admin si besoin). On peut ensuite insÃ©rer des donnÃ©es soit via SQL (`INSERT INTO exemple_personnes (nom, age) VALUES ('Alice', 30);`), soit directement en utilisant un outil comme pgAdmin pour Ã©diter la table.

Lâ€™intÃ©rÃªt de Metabase se rÃ©vÃ¨le lorsquâ€™on veut **visualiser les donnÃ©es** : on peut crÃ©er une *question* en sÃ©lectionnant la table et en appliquant des filtres graphiquement, ou en Ã©crivant une requÃªte SQL et en affichant le rÃ©sultat sous forme de tableau ou de graphique. Par exemple, si la table contient des champs appropriÃ©s, Metabase peut automatiquement proposer des graphes (histogramme des Ã¢ges, etc.).

**Ã‰tape 5 â€“ Utilisation de Metabase pour lâ€™analyse :** Demandez aux Ã©tudiants de **charger un petit jeu de donnÃ©es** (quelques dizaines de lignes suffisent) dans PostgreSQL â€“ cela peut Ãªtre un fichier CSV importÃ© via un outil, ou des inserts SQL fournis. Ensuite, via Metabase, ils peuvent formuler des questions : *Â« Combien de personnes ont moins de 25 ans ? Â»*, *Â« Ã‚ge moyen par catÃ©gorieâ€¦ Â»* etc., soit en mode graphique soit en SQL. Metabase offre un bon compromis pour les dÃ©butants : ils voient le **rÃ©sultat des requÃªtes immÃ©diatement**, peuvent ajuster et corriger facilement. Câ€™est motivant car on obtient aussi des visualisations simples (diagrammes) trÃ¨s rapidement.

**SÃ©curitÃ© de base :** Puisque PostgreSQL est en local, le risque de sÃ©curitÃ© est faible, mais câ€™est lâ€™occasion dâ€™Ã©voquer les notions de **droits utilisateurs** dans un SGBD. On peut montrer comment crÃ©er un utilisateur SQL avec des privilÃ¨ges limitÃ©s, par exemple un rÃ´le *Â« etudiant Â»* qui ne peut que lire certaines tables. Cela introduit les **bonnes pratiques de sÃ©curitÃ©** : ne pas donner les droits admin Ã  tout le monde, compartimenter lâ€™accÃ¨s aux donnÃ©es. De mÃªme, on peut discuter de la nÃ©cessitÃ© de protÃ©ger les accÃ¨s (mots de passe forts, ne pas exposer la base directement sur Internet sans pare-feu, etc.). Enfin, sensibilisez aux attaques comme lâ€™**injection SQL** : comme les Ã©tudiants vont bientÃ´t coder des applications, il est crucial de leur faire comprendre quâ€™il ne faut **jamais** concatÃ©ner naÃ¯vement des entrÃ©es utilisateurs dans des requÃªtes SQL sous peine de gros risques (mais on approfondira ce point en cours de dÃ©veloppement).

## 5. Apprentissage du SQL pas Ã  pas

Nous entrons dans le cÅ“ur du sujet : **manipuler et interroger une base de donnÃ©es relationnelle en SQL**. Lâ€™objectif est quâ€™en quelques sÃ©ances, les Ã©tudiants acquiÃ¨rent une autonomie pour crÃ©er des schÃ©mas, insÃ©rer des donnÃ©es et Ã©crire des requÃªtes dâ€™exploitation (lecture/analytique). On progressera du simple vers le complexe, en alternant apports thÃ©oriques, exemples concrets et exercices pratiques.

### 5.1 Langage de dÃ©finition de donnÃ©es (DDL) : crÃ©ation et modification du schÃ©ma

Le DDL (*Data Definition Language*) regroupe les commandes SQL permettant de crÃ©er ou modifier la structure des objets de base de donnÃ©es (tables, index, contraintes, etc.). On couvre ici les commandes principales :

- **CREATE TABLE :** sert Ã  crÃ©er une table avec ses colonnes, types et contraintes. Par exemple :

```sql
CREATE TABLE Client (
   client_id SERIAL PRIMARY KEY,
   nom VARCHAR(100) NOT NULL,
   email VARCHAR(255) UNIQUE,
   ville VARCHAR(50)
);

```

Ici on crÃ©e une table *Client* avec un id auto-incrÃ©mentÃ© (type SERIAL), une contrainte de clÃ© primaire, lâ€™obligation que *nom* ne soit pas NULL, et une contrainte UNIQUE sur lâ€™email (pour Ã©viter les doublons de courriel).

*Points pÃ©dagogiques:* expliquer les principaux **types SQL** (INTEGER, VARCHAR, DATE, BOOLEAN, etc.), la diffÃ©rence entre **NULL et NOT NULL** (une valeur manquante vs champ obligatoire), la syntaxe des **contraintes** (PRIMARY KEY, UNIQUE, CHECK, DEFAULTâ€¦). Souvent, on introduit aussi la notion dâ€™**auto-incrÃ©ment** (SERIAL ou `AUTO_INCREMENT` en MySQL) pour les PK numÃ©riques. Un exercice possible : *â€œÃ‰crire la commande CREATE TABLE pour la table Produit dâ€™aprÃ¨s le modÃ¨le conÃ§u (id, nom, prix, etc.), en choisissant des types appropriÃ©s et en dÃ©finissant la PK.â€*

- **ALTER TABLE :** permet de modifier une table existante (ajouter une colonne, changer un type, ajouter une contrainte, etc.). Exemple : `ALTER TABLE Client ADD COLUMN age INT;` ajoute une colonne Ã¢ge. Utile pour montrer quâ€™un schÃ©ma peut Ã©voluer, mais aussi signaler que toute modification a un impact (p.ex. si on ajoute une contrainte NOT NULL sur une table dÃ©jÃ  remplie, il faut sâ€™assurer quâ€™aucune ligne ne viole la contrainte). On peut faire pratiquer en demandant dâ€™ajouter une colonne, ou de renommer une colonne (`ALTER TABLE ... RENAME COLUMN ...`), etc.
- **DROP TABLE / DROP ... :** supprime un objet (table, indexâ€¦). **Attention** en prod ! Ces commandes sont destructrices. Pour lâ€™exercice, on peut crÃ©er puis dropper une table temporaire pour voir. Mentionner Ã©ventuellement `DROP TABLE IF EXISTS` (pour Ã©viter erreur si table absente). Pareil pour `DROP DATABASE` (supprimer une base entiÃ¨re â€“ Ã  manipuler avec prÃ©caution).
- **CREATE INDEX :** crÃ©er un index sur une ou plusieurs colonnes. Syntaxe par ex : `CREATE INDEX idx_client_ville ON Client(ville);` pour accÃ©lÃ©rer les recherches par ville. On expliquera que les SGBD crÃ©ent **automatiquement un index pour chaque clÃ© primaire** (et souvent clÃ© unique)[ovhcloud.com](https://www.ovhcloud.com/fr/learn/sql-vs-nosql/#:~:text=Avantages%20de%20SQL)[ovhcloud.com](https://www.ovhcloud.com/fr/learn/sql-vs-nosql/#:~:text=Lors%20de%20l%27utilisation%20de%20ces,coup%20d%27%C5%93il%20%C3%A0%20ces%20propri%C3%A9t%C3%A9s), ce qui fait quâ€™en gÃ©nÃ©ral on nâ€™a pas besoin de crÃ©er un index sur lâ€™id puisque câ€™est la PK. Par contre, sur des colonnes de filtre frÃ©quent (ex: un champ *email* quâ€™on va chercher souvent), un index peut aider. Faire Ã©ventuellement une dÃ©mo : sans index vs avec index (mais sur de petites tables lâ€™impact sera peu visible). Au moins, conceptualiser que lâ€™index se met Ã  jour en mÃªme temps que les donnÃ©es (coÃ»t en Ã©criture, bÃ©nÃ©fice en lecture).
- **FOREIGN KEY :** en SQL, une contrainte FK se dÃ©finit soit dans la crÃ©ation de table, soit via ALTER. Exemple dans `CREATE TABLE Commande (... client_id INT REFERENCES Client(client_id) ...)`. On peut aussi Ã©crire `FOREIGN KEY (client_id) REFERENCES Client(client_id)`. Il est important de mentionner les **actions en cas de suppression** (ON DELETE CASCADE, NO ACTION, SET NULL, etc.) â€“ par exemple, `ON DELETE CASCADE` supprime automatiquement les commandes dâ€™un client si le client est supprimÃ©. Câ€™est un aspect du SGBD garantissant lâ€™intÃ©gritÃ© rÃ©fÃ©rentielle automatiquement. On peut faire manipuler une contrainte FK : crÃ©er deux tables liÃ©es, tenter de violer la contrainte (insertion dâ€™un enregistrement avec FK pointant vers un parent inexistant, voir le refus du SGBD), puis insÃ©rer dans le bon ordre.

**Exercice intÃ©grateur DDL :** reprendre le modÃ¨le de donnÃ©es de lâ€™application cible (par ex. Client-Commande-Produit) et Ã©crire les commandes `CREATE TABLE` pour chaque entitÃ©, avec clÃ©s primaires, Ã©trangÃ¨res et quelques contraintes (NOT NULL sur les champs obligatoires, UNIQUE si pertinent). Une fois les tables crÃ©Ã©es, utiliser `\d` (psql) ou lâ€™interface de Metabase/pgAdmin pour vÃ©rifier la structure, et Ã©ventuellement corriger les erreurs de syntaxe. Cet exercice ancre la comprÃ©hension du schÃ©ma relationnel *implÃ©mentÃ©*.

### 5.2 Langage de manipulation de donnÃ©es (DML) : insÃ©rer, mettre Ã  jour, supprimer des donnÃ©es

Le DML (*Data Manipulation Language*) regroupe les commandes permettant de **modifier le contenu** des tables :

- **INSERT INTO :** ajoute de nouvelles lignes. Deux formes : soit en listant les colonnes et les valeurs, soit en sâ€™appuyant sur lâ€™ordre des colonnes. Exemples :

```sql
INSERT INTO Client(nom, email, ville) VALUES ('Alice', 'alice@example.com', 'Paris');
INSERT INTO Client(nom, ville) VALUES ('Bob', 'Lyon');  -- email sera NULL ici

```

On montre que si on ne spÃ©cifie pas la colonne PK `client_id` (car SERIAL auto), elle se remplira toute seule. Faire attention aux chaÃ®nes de caractÃ¨res (quotÃ©es), aux dates (`'2023-10-01'`), etc. On peut faire insÃ©rer plusieurs lignes dâ€™un coup (plusieurs tuples de VALUES) pour aller plus vite. **Erreur frÃ©quente de dÃ©butant** : oublier une quote, une parenthÃ¨se â€“ profiter pour montrer comment le SGBD rÃ©agit (message dâ€™erreur, etc.) afin quâ€™ils apprennent Ã  dÃ©boguer.

- **UPDATE ... SET ... WHERE :** modifie des enregistrements existants. Exemple : `UPDATE Client SET ville='Marseille' WHERE nom='Alice';` changera la ville dâ€™Alice. **Insister sur la clause WHERE :** sans `WHERE`, *toutes* les lignes seront mises Ã  jour (ex : `UPDATE Client SET ville='Paris';` mettrait "Paris" partout). Câ€™est une classique â€œbouletteâ€ SQL, donc bien prÃ©venir quâ€™un UPDATE/DELETE sans condition affecte toute la table. Astuce : sur un SGBD comme Postgres, on peut faire un `BEGIN` (dÃ©buter une transaction), exÃ©cuter la requÃªte potentiellement risquÃ©e, vÃ©rifier avec un SELECT, puis `ROLLBACK` si câ€™Ã©tait une erreur, pour annuler.
- **DELETE FROM ... WHERE :** supprime des enregistrements. MÃªme principe : sans WHERE -> vide toute la table (prudence). Exemple : `DELETE FROM Client WHERE client_id=5;` supprime le client dâ€™ID 5. On peut expliquer les retours du SGBD du style â€œX rows affectedâ€. Mentionner quâ€™il existe TRUNCATE (pour vider entiÃ¨rement une table trÃ¨s rapidement, en contournant les verrous et sans journaling complet) â€“ câ€™est du DDL plus que DML, mais utile de connaÃ®tre.
- **Transactions (BEGIN, COMMIT, ROLLBACK) :** introduire briÃ¨vement la notion de transaction pour regrouper plusieurs modifications atomiquement. Par exemple, si on doit insÃ©rer une commande et dÃ©crÃ©menter le stock du produit, on voudra que les deux opÃ©rations rÃ©ussissent ou Ã©chouent ensemble â€“ on encapsule dans une transaction. Les propriÃ©tÃ©s **ACID** (AtomicitÃ©, CohÃ©rence, Isolation, DurabilitÃ©) assurent la fiabilitÃ© des transactions[ovhcloud.com](https://www.ovhcloud.com/fr/learn/sql-vs-nosql/#:~:text=Lors%20de%20l%27utilisation%20de%20ces,coup%20d%27%C5%93il%20%C3%A0%20ces%20propri%C3%A9t%C3%A9s)[ovhcloud.com](https://www.ovhcloud.com/fr/learn/sql-vs-nosql/#:~:text=). Sans trop dÃ©tailler (Ã§a peut Ãªtre un cours Ã  part entiÃ¨re), donner lâ€™idÃ©e : *atomicitÃ©* = tout ou rien[ovhcloud.com](https://www.ovhcloud.com/fr/learn/sql-vs-nosql/#:~:text=), *isolation* = une transaction en cours ne voit pas les demi-changements des autres[ovhcloud.com](https://www.ovhcloud.com/fr/learn/sql-vs-nosql/#:~:text=), etc. La plupart du temps, quand on exÃ©cute des commandes via un client SQL, chaque commande est en auto-commit (transaction implicite). Mais dans du code applicatif, on gÃ©rera les transactions explicitement.

**Exercices DML suggÃ©rÃ©s :**

- Remplir la base crÃ©Ã©e prÃ©cÃ©demment avec des donnÃ©es factices : par ex. insÃ©rer 5-10 clients, produits, et quelques commandes. On peut demander aux Ã©tudiants dâ€™Ã©crire les inserts eux-mÃªmes, ou fournir un jeu de tuples Ã  importer. Lâ€™important est quâ€™ils manipulent des valeurs et voient comment les FK imposent lâ€™ordre (dâ€™abord insÃ©rer un client avant sa commande, sinon violation).
- Faire quelques **UPDATE** : changer lâ€™adresse dâ€™un client, le statut dâ€™une commande, etc. VÃ©rifier avec un SELECT que la modif a bien eu lieu.
- Faire quelques **DELETE** : supprimer un produit et voir Ã©ventuellement lâ€™effet sur les commandes (si la FK a ON DELETE CASCADE, elles partent aussi ; sinon la suppression sera bloquÃ©e sâ€™il y a une FK NO ACTION). Tester aussi un DELETE sans WHERE sur une table temporaire pour dramatiser lâ€™importance de la clause WHERE ğŸ˜‰.
- Mettre en Ã©vidence la **cohÃ©rence rÃ©fÃ©rentielle** : que se passe-t-il si on tente de supprimer un client qui a des commandes ? (par dÃ©faut, erreur si FK, sauf si cascade). Que se passe-t-il si on insÃ¨re une commande avec un product_id inconnu ? (erreur FK). Ces expÃ©rimentations concrÃ¨tes aident les Ã©tudiants Ã  comprendre le rÃ´le du SGBD comme **gardien de lâ€™intÃ©gritÃ©** â€“ une grande diffÃ©rence avec une simple feuille Excel.

### 5.3 Interroger les donnÃ©es : le langage des requÃªtes SQL (SELECT, JOIN, etc.)

AprÃ¨s avoir peuplÃ© la base, vient lâ€™essentiel : **savoir lire/exploiter les donnÃ©es** avec des requÃªtes. Câ€™est souvent la partie la plus dense du cours SQL. On la construit progressivement :

- **SELECT * FROM Table :** commencer par lâ€™extraction la plus simple â€“ *Â« sÃ©lectionne toutes les colonnes, toutes les lignes Â»*. Montrer le rÃ©sultat sous forme de tableau. Souligner que lâ€™ordre par dÃ©faut des rÃ©sultats nâ€™est pas garanti (sauf si on impose un tri). Encourager Ã  lister les colonnes explicitement plutÃ´t que `SELECT *` (bonne pratique pour ne rÃ©cupÃ©rer que ce dont on a besoin, amÃ©liorer lisibilitÃ©, etc.).
- **Clauses WHERE (filtres) :** introduire la clause `WHERE` pour filtrer les lignes par condition. Exemples : `SELECT nom, ville FROM Client WHERE ville='Paris';` retourne les clients parisiens. `SELECT * FROM Produit WHERE stock < 5 AND prix > 100;` filtres combinÃ©s, avec opÃ©rateurs de comparaison (=, <, >, <=, >=, <>, !=) et boolÃ©ens (AND, OR, NOT). Ne pas oublier lâ€™usage des quotes pour les textes, et la syntaxe spÃ©ciale pour les patterns (LIKE, %). Par exemple `WHERE nom LIKE 'A%'` pour les noms commenÃ§ant par A. On peut mentionner les expressions rÃ©guliÃ¨res (Postgres `~`) si curieux, mais pas obligatoire.
- **Projection (choix de colonnes) :** montrer quâ€™on peut sÃ©lectionner certaines colonnes seulement, crÃ©er des colonnes calculÃ©es (`SELECT prix * 1.2 AS prix_ttc FROM Produit;`). Parler des fonctions *built-in* (CONCAT, SUBSTR, UPPER, etc. pour manipuler les strings, ou DATE_TRUNC, etc. si besoin) â€“ mais garder Ã§a pour plus tard Ã©ventuellement. Un point important : la **gestion des NULL** (ex: si un email est NULL, un filtre `email = 'alice@x'` ne le retournera pas car NULL nâ€™est â€œÃ©galâ€ Ã  rien, il faut utiliser `IS NULL` pour tester). Faire un apartÃ© sur les trois valeurs logiques (TRUE/FALSE/UNKNOWN) introduites par les NULL.
- **ORDER BY (tri) :** `SELECT * FROM Client ORDER BY nom ASC;` tri alphabÃ©tique. Descendant : `ORDER BY age DESC`. Souligner que sans ORDER BY, lâ€™ordre est arbitraire (surtout en SQL moderne, on nâ€™a pas la garantie de lâ€™ordre dâ€™insertion). On peut trier sur plusieurs colonnes, etc.
- **LIMIT / OFFSET :** (sâ€™ils utilisent Postgres/MySQL) mentionner la possibilitÃ© de limiter le nombre de rÃ©sultats (utile si table trÃ¨s grande, ou pour pagination). Exemple : `SELECT * FROM Produit ORDER BY prix DESC LIMIT 5;` â€“ top 5 des produits les plus chers.

Jusque-lÃ , ce sont des requÃªtes simples sur une seule table. **Exercices** : trouver tous les clients dâ€™une certaine ville, lister les produits en rupture (stock=0), lister les 3 produits les moins chers, etc. Lâ€™idÃ©e est que les Ã©tudiants sâ€™habituent Ã  formuler des critÃ¨res et Ã  lire des rÃ©sultats.

- **JOINS (jointures) :** Le point central pour exploiter un schÃ©ma relationnel multi-table. Expliquer quâ€™une **jointure** combine des lignes de plusieurs tables selon une condition dâ€™appariement (souvent clÃ© Ã©trangÃ¨re = clÃ© primaire). Syntaxe la plus courante : *join interne* avec `SELECT ... FROM A JOIN B ON A.clef = B.clef`. On peut commencer par un exemple : *Â« retrouver la liste des commandes avec le nom du client Â»*. Supposons table *Commande*(id, date, client_id, total) et table *Client*(client_id, nom,â€¦). La requÃªte :

```sql
SELECT Commande.id, Commande.date, Client.nom, Commande.total
FROM Commande
JOIN Client ON Commande.client_id = Client.client_id;

```

Cette **jointure interne** (INNER JOIN) ne retournera que les commandes qui ont un client correspondant (ce qui est normal si la contrainte FK est respectÃ©e). Expliquer le rÃ©sultat : chaque ligne du rÃ©sultat est la combinaison dâ€™une ligne de Commande avec la ligne de Client associÃ©e, les colonnes demandÃ©es sont issues des deux tables. Câ€™est lâ€™Ã©quivalent de Â« pour chaque commande, on va chercher le client correspondant Â». On peut Ã©crire des alias pour simplifier (`FROM Commande AS co JOIN Client AS cl ON co.client_id = cl.client_id`).

Ensuite, mentionner les diffÃ©rentes jointures :

- **INNER JOIN** : ne garde que les correspondances (ce quâ€™on vient de faire).
- **LEFT JOIN** (jointure externe gauche) : garde *toutes* les lignes de la table de gauche, mÃªme si pas de correspondant Ã  droite, les colonnes de droite seront NULL. Utile par exemple pour lister *tous* les clients et leurs commandes, y compris les clients sans commande (ils apparaÃ®tront avec NULL pour les infos de commande). On peut faire un exemple : `SELECT cl.nom, co.id FROM Client cl LEFT JOIN Commande co ON co.client_id = cl.client_id;` â€“ les clients sans commandes auront co.id NULL.
- **RIGHT JOIN** (symÃ©trique, moins utilisÃ© souvent car on peut inverser lâ€™ordre des tables).
- **FULL JOIN** (externe complet, combinant les deux, peu frÃ©quent).
- **CROSS JOIN** (produit cartÃ©sien, toutes combinaisons â€“ rarement souhaitÃ© sauf cas particulier).

Pour dÃ©butants, se concentrer sur INNER et LEFT JOIN, qui couvrent 95% des besoins. Illustrer potentiellement avec un schÃ©ma ou des petits ensembles de donnÃ©es pour voir la diffÃ©rence.

**Exercices sur les jointures :**

- Lister toutes les commandes avec nom du client et Ã©ventuellement dâ€™autres infos liÃ©es (ex: ville du client).
- Lister les lignes de commande (si on a une table dâ€™association) en joignant Produits pour voir le nom du produit au lieu de juste lâ€™ID.
- Trouver des clients sans commandes (requÃªte avec LEFT JOIN filtrÃ©e `WHERE Commande.id IS NULL`).
- Si on a un domaine diffÃ©rent : par ex. *Ã‰tudiants - Inscriptions - Cours*, lister les Ã©tudiants avec les cours auxquels ils sont inscrits (et inversement).

Lâ€™objectif est de rendre les Ã©tudiants Ã  lâ€™aise avec lâ€™idÃ©e quâ€™on peut *combiner plusieurs tables* dans une requÃªte pour obtenir une information complÃ¨te rÃ©pondant Ã  un besoin mÃ©tier.

- **Fonctions dâ€™agrÃ©gation et GROUP BY :** Une fois les jointures acquises, on ajoute la couche *agrÃ©gation*. Ce sont les requÃªtes de type *Â« combien, moyenne, minimum, maximumâ€¦ Â»*. Les fonctions classiques : `COUNT()`, `SUM()`, `AVG()`, `MIN()`, `MAX()`. Par exemple : *Â« Combien de commandes chaque client a passÃ©es ? Â»* -> on peut Ã©crire:

```sql
SELECT cl.nom, COUNT(co.id) AS nb_commandes
FROM Client cl
LEFT JOIN Commande co ON co.client_id = cl.client_id
GROUP BY cl.client_id, cl.nom;

```

Ici on voit la clause `GROUP BY` : on regroupe les rÃ©sultats par client. Toute colonne sÃ©lectionnÃ©e qui nâ€™est pas agrÃ©gÃ©e doit figurer dans le GROUP BY (ex: on groupe par le nom du client pour pouvoir le sÃ©lectionner). Le rÃ©sultat donnera chaque client et le nombre de commandes associÃ©es.

Autres exemples : *Â« Chiffre dâ€™affaire total par client Â»* (`SUM(Commande.total) GROUP BY client`), *Â« Stock moyen des produits par catÃ©gorie Â»* (si on a une catÃ©gorie, `AVG(stock) GROUP BY categorie`), etc. Illustrer aussi `HAVING` pour filtrer sur des agrÃ©gats (par ex. *Â« clients ayant plus de 2 commandes Â»* : on ajouterait `HAVING COUNT(co.id) > 2`).

**Exercices agrÃ©gations :**

- Combien de produits diffÃ©rents ont Ã©tÃ© commandÃ©s dans chaque commande (si table LigneCommande, `COUNT(DISTINCT produit_id) GROUP BY commande_id`).
- Trouver la ville qui a le plus de clients (GROUP BY ville, COUNT(*), ORDER BY COUNT DESC, LIMIT 1).
- Calculer le stock total de produits en magasin (simple SUM sans group by).
- Etc.
- **Sous-requÃªtes et vues :** Si le temps le permet, introduire les sous-requÃªtes (ex: *requÃªte imbriquÃ©e* dans un `WHERE` ou un FROM) pour des cas oÃ¹ une requÃªte doit en filtrer une autre. Par exemple : *Â« produits dont le prix est supÃ©rieur au prix moyen de tous les produits Â»* â€“ on peut faire `WHERE prix > (SELECT AVG(prix) FROM Produit)`. Expliquer que le SGBD peut traiter Ã§a de diffÃ©rentes maniÃ¨res (parfois optimisation en une passe). Mentionner les vues (`CREATE VIEW`) pour sauvegarder une requÃªte complexe et la rÃ©utiliser comme une table virtuelle.
- **EXPLAIN et optimisation de requÃªtes :** Montrer quâ€™on peut prÃ©fixer une requÃªte par `EXPLAIN` (voire `EXPLAIN ANALYZE` sur Postgres) pour obtenir le *plan dâ€™exÃ©cution*. Les dÃ©butants ne comprendront pas tous les dÃ©tails, mais ils verront des mots comme *Seq Scan* (parcours sÃ©quentiel de table) ou *Index Scan* (utilisation dâ€™index). Par exemple, faire une requÃªte avec un filtre sur une colonne indexÃ©e vs non indexÃ©e et voir la diffÃ©rence de plan. Ceci fait le lien avec la partie **index/B-tree** vue en thÃ©orie : un index permet au plan dâ€™Ã©viter le *Seq Scan* sur une grosse table, ce qui est bien plus efficace[use-the-index-luke.com](https://use-the-index-luke.com/fr/sql/anatomie-dun-index/le-b-tree#:~:text=L%27arbre%20de%20recherche%20%28B,que%20j%27en%20parle%20comme). Câ€™est une initiation Ã  lâ€™optimisation : Ã©crire une requÃªte câ€™est bien, comprendre comment le SGBD la rÃ©alise câ€™est mieux pour anticiper les problÃ¨mes de perf. Insister quâ€™on nâ€™Ã©crit pas la boucle de parcours nous-mÃªmes â€“ on dÃ©clare juste quoi chercher en SQL et câ€™est le *moteur de requÃªte* qui dÃ©cide comment (câ€™est lÃ  la force mais aussi la subtilitÃ© du SGBD).

### 5.4 Concepts avancÃ©s : partitionnement, performance et bonnes pratiques SQL

Dans la derniÃ¨re partie du module SQL, on aborde quelques notions avancÃ©es pour Ã©largir la perspective des Ã©tudiants au-delÃ  des bases :

- **Partitionnement de tables :** Lorsquâ€™une table devient trÃ¨s volumineuse (des millions de lignes), il peut Ãªtre judicieux de la **partitionner**, câ€™est-Ã -dire la dÃ©couper physiquement en plusieurs sous-tables tout en la manipulant logiquement comme une seule. PostgreSQL, par exemple, permet de dÃ©clarer une table partitionnÃ©e selon un critÃ¨re (plage de dates, valeur de clÃ©, etc.)[docs.postgresql.fr](https://docs.postgresql.fr/12/ddl-partitioning.html#:~:text=PostgreSQL%20donne%20un%20moyen%20de,La%20d%C3%A9claration%20inclut%20la). Par exemple, on peut partitionner une table *Logs* par annÃ©e de sorte que les requÃªtes sur les logs 2023 nâ€™aillent chercher que dans la partition de 2023 et pas dans les donnÃ©es 2021, 2022, etc. Ce mÃ©canisme amÃ©liore les performances de requÃªte et facilite lâ€™archivage (on peut dÃ©tacher ou supprimer dâ€™un coup les partitions anciennes). Pour illustrer, on peut montrer la syntaxe simple :

```sql
CREATE TABLE Ventes (
   id SERIAL, date DATE, montant NUMERIC
) PARTITION BY RANGE(date);

CREATE TABLE Ventes_2022 PARTITION OF Ventes
   FOR VALUES FROM ('2022-01-01') TO ('2023-01-01');

CREATE TABLE Ventes_2023 PARTITION OF Ventes
   FOR VALUES FROM ('2023-01-01') TO ('2024-01-01');

```

Puis insÃ©rer des ventes sur 2022/2023 et voir quâ€™elles vont dans la bonne partition. Sans entrer dans tous les dÃ©tails (gestion des partitions par la base), lâ€™idÃ©e Ã  retenir est : *le partitionnement dÃ©coupe les donnÃ©es horizontalement, ce qui peut accÃ©lÃ©rer certaines requÃªtes et faciliter la maintenance*. Câ€™est particuliÃ¨rement utile pour les tables de *logs*, *historique*, *donnÃ©es temporelles* trÃ¨s lourdes. On peut mentionner que dâ€™autres SGBD ou solutions utilisent le terme **sharding** lorsque les partitions sont distribuÃ©es sur plusieurs serveurs (notion de base de donnÃ©es distribuÃ©e).

- **Tuning des index et requÃªtes :** Discuter de cas concrets dâ€™optimisation :
    - Choix des index : ex. index composite si on cherche souvent sur [colonne A ET colonne B]. Par contre, multiplier les index sur une table de forte volumÃ©trie peut pÃ©naliser les insertions et consommer de lâ€™espace.
    - RequÃªtes SQL Ã  Ã©viter : SELECT * abusif (ramÃ¨ne trop de donnÃ©es), les sous-requÃªtes corrÃ©lÃ©es non nÃ©cessaires (prÃ©fÃ¨rer une jointure), etc.
    - **Plans dâ€™exÃ©cution :** Ã©voquer ce quâ€™on voit dans un EXPLAIN. Par ex., expliquer ce quâ€™est un *Nested Loop Join*, un *Hash Join*, un *Sort*, un *Sequential Scan*. Pas besoin dâ€™entrer dans les algorithmes en dÃ©tail, mais au moins que le SGBD choisit la mÃ©thode (et quâ€™en gÃ©nÃ©ral, on fait confiance Ã  lâ€™optimiseur, mais quâ€™on peut ajuster via indexes, hints dans certains SGBD, etc.).
    - **Cache et mÃ©moire :** mentionner que les SGBD gardent en mÃ©moire les pages rÃ©cemment accÃ©dÃ©es (cache buffer) pour accÃ©lÃ©rer les lectures rÃ©pÃ©tÃ©es. Donc lire 1000 fois la mÃªme petite table nâ€™est pas 1000 fois plus long quâ€™une fois, grÃ¢ce au cache. Par contre lire sÃ©quentiellement un Ã©norme ensemble de donnÃ©es, Ã§a prend du temps (I/O).
    - **Verrous et concurrence :** pour info, dire que le SGBD gÃ¨re la concurrence via des mÃ©canismes de verrouillage ou versionnement (MVCC dans Postgres). Ceci garantit que deux transactions nâ€™Ã©crasent pas des donnÃ©es lâ€™une de lâ€™autre de maniÃ¨re incohÃ©rente. Les niveaux dâ€™isolation (READ COMMITTED, REPEATABLE READâ€¦) peuvent Ãªtre mentionnÃ©s, mais Ã§a peut rester superficiel si le temps manque.
- **Bonnes pratiques de sÃ©curitÃ© SQL :** Refaire un point sur lâ€™**injection SQL** cÃ´tÃ© application â€“ montrer un exemple simple en pseudo-code dâ€™une app vulnÃ©rable (`query = "SELECT * FROM Client WHERE email='"+ userInput + "'";` et userInput = `' OR '1'='1` qui dÃ©clenche un dump complet). Expliquer quâ€™utiliser des **requÃªtes paramÃ©trÃ©es** ou ORM Ã©vite ce problÃ¨me. CÃ´tÃ© SGBD, rappeler lâ€™importance de la gestion des rÃ´les : ne jamais donner plus de privilÃ¨ges que nÃ©cessaire Ã  un compte applicatif (principe de moindre privilÃ¨ge). Si lâ€™appli nâ€™a besoin que de SELECT, quâ€™on ne lui donne pas les droits de DROP table ! Mentionner aussi les sauvegardes (dump rÃ©gulier), la surveillance des performances (log des requÃªtes lentes), etc., comme parties prenantes de lâ€™administration dâ€™une base de donnÃ©es.

Pour conclure la partie relationnelle, on peut souligner que **SQL reste un langage incontournable** en informatique : il est trÃ¨s prÃ©sent en entreprise, et mÃªme avec lâ€™Ã©mergence de NoSQL, SQL a su Ã©voluer et reste pertinent (certaines bases NoSQL modernes rÃ©introduisent dâ€™ailleurs des langages proches du SQL). Le but du cours est que chaque Ã©tudiant sache concevoir un schÃ©ma simple et Ã©crire des requÃªtes SQL pour exploiter les donnÃ©es, ce qui est atteint via la pratique rÃ©guliÃ¨re sur des cas concrets.
